---
title: "DESeq2 Analysis in R"
author: "Griffin Hill"
date: "4/28/2021"
output: 
  github_document:
    toc: true
    toc_depth: 2
---
```{r setup, include=FALSE}
active = "BesFj"
path = "'/Users/Griffin/Documents/UiT/OneDrive - UiT Office 365/Master\'s proj/Bioinformatics/R_dir/Dseq2-DGE/'"
knitr::opts_knit$set(root.dir = '/Users/Griffin/Documents/UiT/OneDrive - UiT Office 365/Master\'s proj/Bioinformatics/R_dir/Dseq2-DGE/')
directoryBes17Short = "./notrna/all"
knitr::opts_chunk$set(fig.align = 'center')
```
#### A representative example of fjord-offshore differential gene expression (DGE) analysis in Polar cod (*Boreogadus saida*) using DESeq2
This markdown comprises an example analysis using one of the three environmental pairings used in my Msc thesis titled *Transcriptomic basis for differentiation of fjord and coastal Polar cod (Boreogadus saida) populations*. Substantial additional documentation on the possible applications of DESeq2 can be found in its [vignette](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html).

## Setup
Several libraries are used for visualization in addition to DESeq2, which does the actual DGE. 
```{r libraries, results='hide', message=FALSE}
library(DESeq2)
library("pheatmap")
library("RColorBrewer")
library(ggplot2)
library(cowplot)
```

The input is:

1. a directory full of, in this case, output *htseq* files (plain text rows of genes with associated counts) example:

` gene-LOC115528735	1 `  
` gene-LOC115528736	0 `  
` gene-LOC115528737	136 `  
` gene-LOC115528738	0 `  
` gene-LOC115528741	1 `  

2. a sample sheet with sample names, year, and environment type (fjord or offshore) for example:

|Sample |	Treatment |	Year
|---|---|---|
|BesFj1704_L1 |	Fjord |	2017
|BesFj1706_L1 |	Fjord |	2017
|BesFj1707_L1 |	Fjord |	2017

```{r input}
sampleNamesBes17 = read.delim('./Bes17-deseq2ready.txt', header = T)
sampleListBes17 = as.vector(sampleNamesBes17['Sample'])
conditionBes17 = as.vector(sampleNamesBes17[,"Treatment"])
yearBes17 = as.vector(sampleNamesBes17[,"Year"])
sampleFilesBes17 = unlist(lapply(sampleListBes17[,1], paste0, "_readcount_notrna_2short.txt"))
```
The vectors of each column in the sample list are then used as inputs to create a DESeq2-ready dataframe.
```{r DESeq2 ready}
sampleTableBes17Short <- data.frame(sampleName = sampleListBes17,
                                 fileName = sampleFilesBes17,
                                 condition = conditionBes17,
                                 year = factor(yearBes17))
head(sampleTableBes17Short)
```
Once outliers are identified (downstream during sample to sample distance analysis) they can be effectively removed at this step. Otherwise, the *DESeq2DataSet* (DDS) can be generated via *DESeqDataSetFromHTSeqCount* because we are working from *htseq* read counts.
At this stage different factors can be fed to "design" to determine how the dataset is created. In my analysis, condition (fjord vs. offshore) is the most interesting factor so it is the key to my dataset design.
```{r DDS, warning=FALSE}
ddsHTSeqBes17Short <- DESeqDataSetFromHTSeqCount(sampleTable = sampleTableBes17Short,
                                              directory = directoryBes17Short,
                                              design= ~ condition)
```
## Quality assurance and control (QAQC)
The first step of QAQC is removing genes (rows in the dataset) with less than 5 reads. Here we can see the difference in rows pre and post filtering.
```{r low reads}
keepBes17Short <-rowSums(counts(ddsHTSeqBes17Short)) >=5
ddsHTSeqBes17Short_keep <- ddsHTSeqBes17Short[keepBes17Short,]
nrow(ddsHTSeqBes17Short)
nrow(ddsHTSeqBes17Short_keep) 
```
Simple normalization is done via the built in *vst* function.
VST calculates a variance stabilizing transformation from the fitted dispersion-mean relation(s) and then transforms the count data (normalized by division by the size factors or normalization factors). This yields a matrix of values which are now approximately homoskedastic (having constant variance along the range of mean values). The transformation also normalizes with respect to library size. 
The "cooks" assay can then be used to check for samples identified as outliers based on Cook's distance. The default threshold for this is to use the 99% quantile of the F(p,m-p) distribution (with p the number of parameters including the intercept and m number of samples). A return of ` NULL ` signifies no outliers were identified.
At this stage: rows = genes (gene id used to capture greatest number of reads in alignment), columns = samples
colData can be used to extract condition and size factor by sample (row)
```{r normalization}
normalizedBes17Short <- vst(ddsHTSeqBes17Short_keep,blind = F)
assays(ddsHTSeqBes17Short_keep)[["cooks"]]
```
The next step is a graphical quality check using the top 100 genes normalized by read counts to construct a heatmap of gene representation by sample.
```{r graphical qc}
selectBes17Short <- order(rowMeans(counts(ddsHTSeqBes17Short_keep,normalized=FALSE)),
                       decreasing=TRUE)[1:100] # number of top genes
Bes17qa <- as.data.frame(colData(ddsHTSeqBes17Short_keep))[,"condition"]

assayBes17normal = assay(normalizedBes17Short[selectBes17Short,]) 
pheatmap(assayBes17normal, cluster_rows=FALSE, show_rownames=T, show_colnames=TRUE,  
         cluster_cols=FALSE, main="Bes17 2Short heatmap, VST normalized data, top 100 genes by normalized read counts", fontsize=5)
```
Next, the sample to sample distances are compared. This is where individual sample outliers emerge most prominently.
A heatmap of this distance matrix gives us an overview over similarities and dissimilarities between samples. We have to provide a hierarchical clustering hc to the heatmap function based on the sample distances, or else the heatmap function would calculate a clustering based on the distances between the rows/columns of the distance matrix.
```{r sample distance}
sampleDists <- dist(t(assay(normalizedBes17Short)))
sampleDistMatrix <- as.matrix(sampleDists, rownames = TRUE)
colors <- colorRampPalette( rev(brewer.pal(9, "RdYlBu")) )(255)

pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         treeheight_col = 10,
         treeheight_row = 10,
         show_colnames= T,
         show_rownames = T,
         col=colors,
         fontsize=6,
         legend=FALSE,
         main= paste("Bes17 2short sample-to-sample distance",as.character(Sys.time())))
```

This sample to sample distance plotting is done iteratively as outliers are removed to find the most reasonable dataset. In this case we can see that BF 1714, 1716 are likely outliers. This removal is based on qualitative visual assessment, but errs on the side of including rather than removing individuals.
```{r outlier remake}
Bes_outliers = c("BesFj1716_L1", "BesFj1714_L2")
normalized_df_Bes = as.data.frame(assay(normalizedBes17Short))
Bes_noouts = normalized_df_Bes[,!(names(normalized_df_Bes) %in% Bes_outliers)] 

sampleDists_noouts_Bes <- dist(t(Bes_noouts))
sampleDistMatrix_noouts_Bes <- as.matrix(sampleDists_noouts_Bes, rownames = TRUE)

pheatmap(sampleDistMatrix_noouts_Bes,
         clustering_distance_rows=sampleDists_noouts_Bes,
         clustering_distance_cols=sampleDists_noouts_Bes,
         treeheight_col = 10,
         treeheight_row = 10,
         show_colnames= T,
         show_rownames = T,
         col=colors,
         fontsize=6,
         legend=FALSE,
         main= paste("Bes17 2short sample-to-sample distance",as.character(Sys.time())))
```
Now the DDS needs to be remade without outliers to make sure we are carrying the right dataset forward and updating the relevant variables.
```{r DDS no outs, results='hide', warning=FALSE}
sampleTableBes17Short = sampleTableBes17Short[!sampleTableBes17Short$Sample %in% Bes_outliers, ]

ddsHTSeqBes17Short <- DESeqDataSetFromHTSeqCount(sampleTable = sampleTableBes17Short,
                                              directory = directoryBes17Short,
                                              design= ~ condition)
keepBes17Short <-rowSums(counts(ddsHTSeqBes17Short)) >=5
ddsHTSeqBes17Short_keep <- ddsHTSeqBes17Short[keepBes17Short,]
normalizedBes17Short <- vst(ddsHTSeqBes17Short_keep,blind = F)
```
## PCA plotting
```{r PCA setup, message=FALSE}
library(genefilter)
library(ggrepel)
library(plotly)
```
It is important to consider components in the PCA beyond the first two so here's a function modifying the DESeq2 *plotPCA* function to take which components are to be compared as arguments.
``` {r plot PCA any, results='hide'}
plotPCA.any <- function (object, PCAa = 1, PCAb = 2, intgroup = "condition", ntop = 500, returnData = FALSE) 
{
  rv <- rowVars(assay(object))
  select <- order(rv, decreasing = TRUE)[seq_len(min(ntop, 
                                                     length(rv)))]
  pca <- prcomp(t(assay(object)[select, ]))
  percentVar <- pca$sdev^2/sum(pca$sdev^2)
  if (!all(intgroup %in% names(colData(object)))) {
    stop("the argument 'intgroup' should specify columns of colData(dds)")
  }
  intgroup.df <- as.data.frame(colData(object)[, intgroup, drop = FALSE])
  group <- if (length(intgroup) > 1) {
    factor(apply(intgroup.df, 1, paste, collapse = " : "))
  }
  else {
    colData(object)[[intgroup]]
  }
  ## Select the PCAs and percentVar that you like instead of 1 and 2
  d <- data.frame(PCa = pca$x[, PCAa], PCb = pca$x[, PCAb], group = group, 
                  intgroup.df, name = colnames(object))
  if (returnData) {
    attr(d, "percentVar") <- percentVar[1:4]
    return(d)
  }
  ggplot(data = d, aes_string(x = "PCa", y = "PCb", color = "group", label = "name")) + 
    geom_point(size = 1.5) + 
    xlab(paste0("PC",PCAa,": ", round(percentVar[PCAa] * 100), "% variance")) + 
    ylab(paste0("PC",PCAb,": ", round(percentVar[PCAb] * 100), "% variance")) + 
    geom_text(nudge_x = 1, nudge_y = -1, size = 1.1) +
    stat_ellipse()
}

```
This function can then be used to compare different PCA approaches, though PC1 and PC2 are the most explanatory with PC3 and PC4 explaining less than 10% of observed variance.
```{r PCA plots, echo=FALSE, fig.width=10}
plot_grid(
  plotPCA.any(normalizedBes17Short),
  plotPCA.any(normalizedBes17Short, PCAb = 3),
  plotPCA.any(normalizedBes17Short, PCAb = 4), nrow = 1, labels = "AUTO")
```
The same underlying data can be used to make a 3D PCA at this stage, though it is not much more useful than a grid of the multiple PCA comparisons on their own.
```{r 3D PCA, warning=FALSE, eval=FALSE}
plotPCA.3d <- function (object, intgroup = "condition", ntop = 500, returnData = FALSE) 
{
  rv <- rowVars(assay(object))
  select <- order(rv, decreasing = TRUE)[seq_len(min(ntop, 
                                                     length(rv)))]
  pca <- prcomp(t(assay(object)[select, ]))
  percentVar <- pca$sdev^2/sum(pca$sdev^2)
  if (!all(intgroup %in% names(colData(object)))) {
    stop("the argument 'intgroup' should specify columns of colData(dds)")
  }
  intgroup.df <- as.data.frame(colData(object)[, intgroup, drop = FALSE])
  group <- if (length(intgroup) > 1) {
    factor(apply(intgroup.df, 1, paste, collapse = " : "))
  }
  else {
    colData(object)[[intgroup]]
  }
  ## Select the PCAs and percentVar that you like instead of 1 and 2
  d <- data.frame(PC1 = pca$x[, 1], PC2 = pca$x[, 2], PC3 = pca$x[, 3], group = group, 
                  intgroup.df, name = colnames(object))
  if (returnData) {
    attr(d, "percentVar") <- percentVar[1:3]
    return(d)
  }
  fig <- plot_ly(d, x = ~PC1, y = ~PC2, z = ~PC3, color = ~group, text = row.names(d), hoverinfo = "text")
  fig <- fig %>% add_markers()
  fig <- fig %>% layout(scene = list(xaxis = list(title = paste0("PC1: ",signif(percentVar[1],3)*100,"% variance")),
                                     yaxis = list(title = paste0("PC2: ",signif(percentVar[2],3)*100,"% variance")),
                                     zaxis = list(title = paste0("PC3: ",signif(percentVar[3],3)*100,"% variance"))))
  fig
}
plotPCA.3d(normalizedBes17Short)
```
![Besselfjord 3D PCA](Bess3d.png)

## Results
The *DESeq* and *results* functions in DESeq2 allows for the extraction of the actual relative differential gene expression (the genes being differentially expressed) based on all the filtering and normalization done so far. The resulting genes at this stage can be sorted by p value and exported as csv once coerced to dataframe format.
```{r results}
dge_Bes17Short_keep <- DESeq(ddsHTSeqBes17Short_keep, parallel = TRUE)

results_Bes17_treatment <- results(dge_Bes17Short_keep, contrast=c("condition","Fjord","Offshore"))

summary(results_Bes17_treatment) # probably worth saving

res_Bes17_treatment_ordered <- results_Bes17_treatment[order(results_Bes17_treatment$padj),]
sum(results_Bes17_treatment$padj < 0.01, na.rm=TRUE) #padj = p value adjusted for multiple testing, number of genes padj < 0.01:

# plot of counts and log2 FC of DESeq results table object
plotMA(results_Bes17_treatment, ylim=c(-3,3), colSig = "red", main = "Counts and Log2FC from DESeq results, sig in red") 

ordered_Bes17frame <- as.data.frame(rownames(res_Bes17_treatment_ordered))
ordered_Bes17frame <- na.omit(cbind(ordered_Bes17frame,res_Bes17_treatment_ordered$pvalue,res_Bes17_treatment_ordered$padj,res_Bes17_treatment_ordered$log2FoldChange))
ordered_Bes17frame_sig <- ordered_Bes17frame[ordered_Bes17frame$`res_Bes17_treatment_ordered$padj` < 0.1,]
head(ordered_Bes17frame_sig)
```
This list of genes acts as the input for *FishEnrichr* gene annotation after gene ID conversion via the NCBI *eFetch Utility* (see [github pipeline](https://github.com/gghill/thesis-RNAseq/blob/main/pipeline.md).
The list of significantly differentially expressed gene ontologies (GO) is then used as the input for the final GO visualization in R. This input includes the annotation term and gene ID as well as a number of significance measures. In this case the conversion from from csv to txt via excel has caused the overlap (a fraction) to be converted to a date. Overlap is not used in this analysis, but would require special treatment prior to import to avoid this unwanted conversion.
```{r GO setup, message=FALSE, echo=FALSE}
library(simplifyEnrichment)
Bes17_GO = read.delim("/Users/Griffin/Documents/UiT/OneDrive - UiT Office 365/Master's proj/Results/Bes17/finalish_Bes17_GO_Biological_Process_table.txt", header = T)
head(Bes17_GO)
```
```{r GO vis}
go_sig = Bes17_GO[Bes17_GO$Adjusted.P.value<.1,]
go_id = go_sig$GO_id
mat = GO_similarity(go_id, ont = "BP")
df = simplifyGO(mat, fontsize_range = c(10,18), min_term = 1, draw_word_cloud = T)
```
Depending on the number of GO terms and clusters, the default plotting function may not provide the most legible result. In this case the table created via the *Go_similarity* and *simplifyGo* functions can be used to create a custom heatmap. *simplifyGO* can be assigned to a dataframe instead of just a plot, which is used as the input for our custom heatmap. In this case the GO terms were reduced to some general categories so clusters could be combined to create a more representative figure. This visualization exhibits the overlap between GO IDs and the terms representing the overarching biological processes. Only GO IDs corresponding to differentially expressed genes are included at this stage in analysis.

For most sites, the default plotting produced acceptable plots so this next step is highly optional/situational.
```{r custom GO, fig.width=10, warning=FALSE}
row.names(df) = df$id
simple_terms = c("MAPK inactivation", "chromosome condensation/segregation","response to methylmercury", "chromosome condensation/segregation", "chromosome condensation/segregation", "MAPK inactivation","chromosome condensation/segregation")
df_terms = cbind(df, simple_terms)
map = as.data.frame(df_terms$simple_terms)
rownames(map) = df$id
colnames(map) = "GO_term"
colors <- colorRampPalette( rev(brewer.pal(9, "RdYlBu")) )(255)
anno_colors = list(
  GO_term = c("MAPK inactivation" = "#EDF8FB", 
              "chromosome condensation/segregation" = "#66C2A4",
              "response to methylmercury" = "#238B45")
)
pheatmap(mat,
         clustering_distance_rows=dist(mat),
         clustering_distance_cols=dist(mat),
         show_colnames= T,  
         treeheight_row = 0, 
         treeheight_col = 0,
         show_rownames = T,
         annotation_col = map,
         annotation_colors = anno_colors,
         annotation_names_row = T,
         annotation_row = map,
         annotation_names_col = T,
         col=colors,
         fontsize=10,
         legend=T)
```